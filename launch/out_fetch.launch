<launch>
  <node name="speech_to_roman"
        pkg="teach_spot" type="speech_to_roman.py" >
    <remap from="~output" to="/Tablet/voice_roman" />
  </node>
  <include file="$(find teach_spot)/launch/speech_recognition.launch" >
    <arg name="language" default="ja-JP" />
    <arg name="continuous" default="true" />
  </include>

  <node name="dr_spaam_lidar_person_detection"
        pkg="jsk_perception" type="lidar_person_detection_node.py"
        output="screen">
    <remap from="~input" to="/base_scan" />
    <rosparam subst_value="true" >
      map_link: /map
      weight_file: "$(find jsk_perception)/trained_data/lidar_person_detection/ckpt_jrdb_ann_dr_spaam_e20.pth"
      detector_model: "DR-SPAAM"
      conf_thresh: 0.8
      stride: 1
      panoramic_scan: false
      gpu: -1
    </rosparam>
  </node>

</launch>
